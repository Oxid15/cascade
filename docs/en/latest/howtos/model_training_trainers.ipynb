{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training using trainers\n",
    "This use-case is model training - the same, but now the usage of Trainer will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torchvision\n",
    "# !pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cascade.data as cdd\n",
    "import cascade.models as cdm\n",
    "from cascade.utils.torch import TorchModel\n",
    "from cascade.utils.sklearn import SkMetric\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.0-alpha'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cascade\n",
    "cascade.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_ROOT = 'data'\n",
    "INPUT_SIZE = 784\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseModifier(cdd.Modifier):\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self._dataset[index]\n",
    "        img += torch.rand_like(img) * 0.1\n",
    "        img = torch.clip(img, 0, 255)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_ds = torchvision.datasets.MNIST(root=MNIST_ROOT,\n",
    "                                     train=True, \n",
    "                                     transform=F.to_tensor,\n",
    "                                     download=True)\n",
    "test_ds = torchvision.datasets.MNIST(root=MNIST_ROOT, \n",
    "                                    train=False, \n",
    "                                    transform=F.to_tensor)\n",
    "\n",
    "train_ds = cdd.Wrapper(train_ds)\n",
    "train_ds.describe(\"This is MNIST dataset of handwritten images, TRAIN PART\")\n",
    "test_ds = cdd.Wrapper(test_ds)\n",
    "\n",
    "train_ds = NoiseModifier(train_ds)\n",
    "test_ds = NoiseModifier(test_ds)\n",
    "\n",
    "# We will constraint the number of samples to speed up learning in example\n",
    "train_ds = cdd.CyclicSampler(train_ds, 10000)\n",
    "test_ds = cdd.CyclicSampler(test_ds, 5000)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_ds, \n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(dataset=test_ds,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'cascade.data.cyclic_sampler.CyclicSampler', 'description': None, 'tags': [], 'comments': [], 'links': [], 'type': 'dataset', 'len': 10000}, {'name': '__main__.NoiseModifier', 'description': None, 'tags': [], 'comments': [], 'links': [], 'type': 'dataset', 'len': 60000}, {'name': 'cascade.data.dataset.Wrapper', 'description': 'This is MNIST dataset of handwritten images, TRAIN PART', 'tags': [], 'comments': [], 'links': [], 'type': 'dataset', 'len': 60000, 'obj_type': \"<class 'torchvision.datasets.mnist.MNIST'>\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, y):\n",
    "         out = self.l1(y)\n",
    "         out = self.relu(out)\n",
    "         out = self.l2(out)\n",
    "\n",
    "         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Cascade's wrapper is defined. The most of the interactions with pytorch modules is already implemented in `cascade.utils.TorchModel` so we need to only define how to train and evaluate this model.  \n",
    "  \n",
    "The difference between previous example and this one is in the `fit` function - now it only fits one epoch per call and doesn't need additional logging - Trainer will cover this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(TorchModel):\n",
    "    # In train we copy-paste regular pytorch trainloop, \n",
    "    # but use self._model, where our SimpleNN is placed\n",
    "    def fit(self, train_dl, lr, *args, **kwargs):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.Adam(self._model.parameters(), lr=lr)\n",
    "\n",
    "        ds_size = len(train_dl)\n",
    "        for x, (imgs, labels) in enumerate(train_dl): \n",
    "            imgs = imgs.reshape(-1, self._model.input_size)\n",
    "\n",
    "            out = self._model(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step() \n",
    "\n",
    "\n",
    "    # Evaluate function takes the metrics from arguments\n",
    "    # and populates self.metrics without returning anything\n",
    "    def evaluate(self, test_dl, metrics, *args, **kwargs):\n",
    "        pred = []\n",
    "        gt = []\n",
    "        for imgs, labels in tqdm(test_dl): \n",
    "            imgs = imgs.reshape(-1, self._model.input_size)\n",
    "            out = torch.argmax(self._model(imgs, *args, **kwargs), -1)\n",
    "\n",
    "            pred.append(out)\n",
    "            gt.append(labels)\n",
    "\n",
    "        pred = torch.concat(pred).detach().numpy()\n",
    "        gt = torch.concat(gt).detach().numpy()\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric.compute(gt, pred)\n",
    "            self.add_metric(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "LR = 1e-3\n",
    "\n",
    "# Classifier will initialize SimpleNN with all the parameters passed\n",
    "# but some of them are not for the SimpleNN, but to be recorded in metadata\n",
    "model = Classifier(SimpleNN,\n",
    "    # These arguments are needed by SimpleNN, \n",
    "    # but passed as keywords to be recorded in meta\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=100,\n",
    "    num_classes=10,\n",
    "    # These arguments will be skipped by SimpleNN,\n",
    "    # but will be added to meta\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    lr=LR,\n",
    "    bs=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trainer\n",
    "Let's set up logging first to catch trainer's logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    level='INFO'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cascade.trainers import BasicTrainer\n",
    "\n",
    "trainer = BasicTrainer('trainer_repo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main method of course is train\n",
    "It will do all the stuff needed for us\n",
    "including training, evaluating, saving and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Training started with parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.trainers.trainer:repo is Repo in trainer_repo of 1 lines\n",
      "INFO:cascade.trainers.trainer:line is 00000\n",
      "INFO:cascade.trainers.trainer:training will last 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:04<00:00, 101.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 0\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.874, created_at=2024-08-24 11:08:21.482021+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:04<00:00, 122.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 1\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.8956, created_at=2024-08-24 11:08:21.482021+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:04<00:00, 118.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 2\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.9092, created_at=2024-08-24 11:08:21.482021+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:04<00:00, 115.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 3\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.9202, created_at=2024-08-24 11:08:21.482021+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:04<00:00, 121.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 4\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.919, created_at=2024-08-24 11:08:21.482021+00:00)\n",
      "INFO:cascade.trainers.trainer:Training finished in 1 minute\n",
      "INFO:cascade.trainers.trainer:repo was Repo in trainer_repo of 1 lines\n",
      "INFO:cascade.trainers.trainer:line was 00000\n",
      "INFO:cascade.trainers.trainer:training ended on 4 epoch\n",
      "INFO:cascade.trainers.trainer:Parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.trainers.trainer:Metrics:\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.919, created_at=2024-08-24 11:08:21.482021+00:00)\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    model,\n",
    "    train_data=train_dl,\n",
    "    test_data=test_dl,\n",
    "    train_kwargs={'lr': LR, 'bs': BATCH_SIZE}, # will be passed into model.fit()\n",
    "    test_kwargs={\"metrics\": [SkMetric(\"accuracy_score\")]}, # will be passed into model.evaluate()\n",
    "    epochs=NUM_EPOCHS,\n",
    "    start_from=None, # can start from checkpoint if line name is specified,\n",
    "    save_strategy=2,\n",
    "    eval_strategy=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "We can obtain the results of training from trainer's meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'cascade.trainers.trainer.BasicTrainer', 'epochs': 5, 'eval_strategy': 1, 'save_strategy': 2, 'description': None, 'tags': [], 'comments': [], 'links': [], 'type': 'trainer', 'training_started_at': DateTime(2024, 8, 24, 14, 8, 21, 498283, tzinfo=Timezone('Europe/Moscow')), 'training_ended_at': DateTime(2024, 8, 24, 14, 9, 45, 93067, tzinfo=Timezone('Europe/Moscow'))}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from checkpoint\n",
    "Let's try continue learning where we finished using the same line as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Training started with parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.trainers.trainer:repo is Repo in trainer_repo of 1 lines\n",
      "INFO:cascade.trainers.trainer:line is 00000\n",
      "INFO:cascade.trainers.trainer:started from model 9\n",
      "INFO:cascade.trainers.trainer:training will last 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:04<00:00, 108.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 0\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.9408, created_at=2024-08-24 11:13:04.420271+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 89.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 1\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.9378, created_at=2024-08-24 11:13:04.420271+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:04<00:00, 121.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 2\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.934, created_at=2024-08-24 11:13:04.420271+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:04<00:00, 118.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 3\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.9398, created_at=2024-08-24 11:13:04.420271+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:04<00:00, 124.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.trainers.trainer:Epoch: 4\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.939, created_at=2024-08-24 11:13:04.420271+00:00)\n",
      "INFO:cascade.trainers.trainer:Training finished in 1 minute\n",
      "INFO:cascade.trainers.trainer:repo was Repo in trainer_repo of 1 lines\n",
      "INFO:cascade.trainers.trainer:line was 00000\n",
      "INFO:cascade.trainers.trainer:started from model 9\n",
      "INFO:cascade.trainers.trainer:training ended on 4 epoch\n",
      "INFO:cascade.trainers.trainer:Parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.trainers.trainer:Metrics:\n",
      "INFO:cascade.trainers.trainer:SkMetric(name=accuracy_score, value=0.939, created_at=2024-08-24 11:13:04.420271+00:00)\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    model,\n",
    "    train_data=train_dl,\n",
    "    test_data=test_dl,\n",
    "    train_kwargs={'lr': LR, 'bs': BATCH_SIZE},\n",
    "    test_kwargs={'metrics': [SkMetric(\"accuracy_score\")]},\n",
    "    epochs=5,\n",
    "    start_from='00000',\n",
    "    save_strategy=4,\n",
    "    eval_strategy=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SkMetric(name=accuracy_score, value=0.939, created_at=2024-08-24 11:13:04.420271+00:00)], [SkMetric(name=accuracy_score, value=0.939, created_at=2024-08-24 11:13:04.420271+00:00)], [SkMetric(name=accuracy_score, value=0.939, created_at=2024-08-24 11:13:04.420271+00:00)], [SkMetric(name=accuracy_score, value=0.939, created_at=2024-08-24 11:13:04.420271+00:00)], [SkMetric(name=accuracy_score, value=0.939, created_at=2024-08-24 11:13:04.420271+00:00)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cascade_full_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "faab9700dd378963078e8736d2f2a2135ebae0340eb64481dd59710303e6f8c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
