{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline building\n",
    "This use-case is pipeline building. For this example the task of classification on MNIST is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cascade.data as cdd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cascade\n",
    "cascade.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_ROOT = 'data'\n",
    "\n",
    "train_ds = torchvision.datasets.MNIST(root=MNIST_ROOT,\n",
    "                                     train=True, \n",
    "                                     transform=F.to_tensor,\n",
    "                                     download=True)\n",
    "test_ds = torchvision.datasets.MNIST(root=MNIST_ROOT, \n",
    "                                    train=False, \n",
    "                                    transform=F.to_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding metadata\n",
    "But in the end we need not only loaded dataset, but the container for metadata we can store. So the next step is to link these datasets to Cascade's objects. The most simple way is to use `cascade.data.Wrapper`.  \n",
    "  \n",
    "Suppose we also need to write some data description to be able to know on which data our model was trained. We can do it using `meta_prefix` keyword in the constructor of any dataset.   \n",
    "It accepts python dictionaries of any serializable objects. We will pass short description in metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = cdd.Wrapper(train_ds, \n",
    "    meta_prefix={\n",
    "        'desc': 'This is MNIST dataset of handwritten images'\n",
    "    })\n",
    "test_ds = cdd.Wrapper(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying noise\n",
    "Let's say we want to apply noise to an image.  \n",
    "*We will use hardcoded magnitude to simplify an example.*  \n",
    "To do this we need to make a Modifier. Modifier wraps another dataset and applies a function to its elements in a lazy way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseModifier(cdd.Modifier):\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self._dataset[index] # get the data from Wrapper, which is _dataset for this Modifier\n",
    "        img += torch.rand_like(img) * 0.1 # apply random noise with fixed magnitude\n",
    "        img = torch.clip(img, 0, 255)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply the noise to the images!\n",
    "train_ds = NoiseModifier(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing metadata\n",
    "To view final metadata of the pipeline we can see what `get_meta` method gives:  \n",
    "It is the list of dicts with metadata of each block. First is NoiseModifier and the second is Wrapper around MNIST Dataset with our custom description.  \n",
    "Using keyword `meta_prefix` and method `update_meta` we can add any info we want to the object's metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '__main__.NoiseModifier', 'type': 'dataset', 'len': 60000},\n",
       " {'name': 'cascade.data.dataset.Wrapper',\n",
       "  'desc': 'This is MNIST dataset of handwritten images',\n",
       "  'type': 'dataset',\n",
       "  'len': 60000,\n",
       "  'obj_type': \"<class 'torchvision.datasets.mnist.MNIST'>\"}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready to train model\n",
    "Now we can set the batch size and pass our pipeline to the DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainldr = torch.utils.data.DataLoader(dataset=train_ds, \n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       shuffle=True)\n",
    "testldr = torch.utils.data.DataLoader(dataset=test_ds,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also:\n",
    "[Train models](model_training.html)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1eab4963f8bb4f252819dbce5af8175fe150793bc166a28b75f990b50d08af03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
