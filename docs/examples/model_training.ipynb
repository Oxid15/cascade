{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "This use-case is model training.  \n",
    "By going through this you will know how to use Cascade for metadata tracking, hyperparameter tuning and model selection.  \n",
    "  \n",
    "Previous part is the pipeline building and is taken without comments.  \n",
    "For more detailed description of it see Pipeline building example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cascade.data as cdd\n",
    "import cascade.models as cdm\n",
    "import cascade.utils as cdu\n",
    "import cascade.meta as cde\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cascade\n",
    "cascade.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data pipeline\n",
    "This part will be without comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_ROOT = 'data'\n",
    "INPUT_SIZE = 784\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.2649402618408203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9912422,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31202a62b0284ecca84b20391917cc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.16490745544433594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 28881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f65e40a79f4b5aa88b0ff42ef6b5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.20150375366210938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1648877,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06af0b9e5734709b618892adb5b042e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.1779944896697998,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4542,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc07d440ddb54a3daee7f2515f0457d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NoiseModifier(cdd.Modifier):\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self._dataset[index]\n",
    "        img += torch.rand_like(img) * 0.1\n",
    "        img = torch.clip(img, 0, 255)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_ds = torchvision.datasets.MNIST(root=MNIST_ROOT,\n",
    "                                     train=True, \n",
    "                                     transform=F.to_tensor,\n",
    "                                     download=True)\n",
    "test_ds = torchvision.datasets.MNIST(root=MNIST_ROOT, \n",
    "                                    train=False, \n",
    "                                    transform=F.to_tensor)\n",
    "\n",
    "train_ds = cdd.Wrapper(train_ds, \n",
    "    meta_prefix={\n",
    "        'desc': 'This is MNIST dataset of handwritten images, TRAIN PART'\n",
    "    })\n",
    "test_ds = cdd.Wrapper(test_ds)\n",
    "\n",
    "train_ds = NoiseModifier(train_ds)\n",
    "test_ds = NoiseModifier(test_ds)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_ds, \n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(dataset=test_ds,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '__main__.NoiseModifier', 'type': 'dataset', 'len': 60000},\n",
       " {'name': 'cascade.data.dataset.Wrapper',\n",
       "  'desc': 'This is MNIST dataset of handwritten images, TRAIN PART',\n",
       "  'type': 'dataset',\n",
       "  'len': 60000,\n",
       "  'obj_type': \"<class 'torchvision.datasets.mnist.MNIST'>\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "Before training we need to define our model. We need regular nn.Module and Cascade's wrapper around it.  \n",
    "  \n",
    "Module defined without any specific changes in the original pytorch code, except now it accepts `*args` and `**kwargs` in `__init__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, y):\n",
    "         out = self.l1(y)\n",
    "         out = self.relu(out)\n",
    "         out = self.l2(out)\n",
    "\n",
    "         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Cascade's wrapper is defined. The most of the interaction with pytorch modules are already implemented in `cascade.utils.TorchModel` so we need to only define how to train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(cdu.TorchModel):\n",
    "    # In train we copy-paste regular pytorch trainloop, \n",
    "    # but use self._model, where our SimpleNN is placed\n",
    "    def fit(self, train_dl, num_epochs, lr, *args, **kwargs):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.Adam(self._model.parameters(), lr=lr)\n",
    "\n",
    "        ds_size = len(train_dl)\n",
    "        for epoch in range(num_epochs):\n",
    "            for x, (imgs, labels) in enumerate(train_dl): \n",
    "                imgs = imgs.reshape(-1, self._model.input_size)\n",
    "\n",
    "                out = self._model(imgs)\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step() \n",
    "\n",
    "                if x % 500 == 0:\n",
    "                    print (f'Epochs [{epoch}/{num_epochs}], Step[{x}/{ds_size}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Evaluate function takes the metrics from arguments\n",
    "    # and populates self.metrics without returning anything\n",
    "    def evaluate(self, test_dl, metrics_dict, *args, **kwargs):\n",
    "        pred = []\n",
    "        gt = []\n",
    "        for imgs, labels in tqdm(test_dl): \n",
    "            imgs = imgs.reshape(-1, self._model.input_size)\n",
    "            out = torch.argmax(self._model(imgs, *args, **kwargs), -1)\n",
    "\n",
    "            pred.append(out)\n",
    "            gt.append(labels)\n",
    "\n",
    "        pred = torch.concat(pred).detach().numpy()\n",
    "        gt = torch.concat(gt).detach().numpy()\n",
    "\n",
    "        for metric_name in metrics_dict:\n",
    "            self.metrics[metric_name] = metrics_dict[metric_name](gt, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "Now we are ready to train our model. We define hyperparameters and pass them to our wrapper. Wrapper accepts pytorch module's class and all the parameters that are needed to initialize it.  \n",
    "Additionally we pass keyword arguments that are connected to training. It is done to add them to the model's metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs [0/2], Step[0/6000], Loss: 2.2508\n",
      "Epochs [0/2], Step[500/6000], Loss: 0.5748\n",
      "Epochs [0/2], Step[1000/6000], Loss: 0.3194\n",
      "Epochs [0/2], Step[1500/6000], Loss: 0.3331\n",
      "Epochs [0/2], Step[2000/6000], Loss: 0.3598\n",
      "Epochs [0/2], Step[2500/6000], Loss: 0.4646\n",
      "Epochs [0/2], Step[3000/6000], Loss: 0.1491\n",
      "Epochs [0/2], Step[3500/6000], Loss: 0.1080\n",
      "Epochs [0/2], Step[4000/6000], Loss: 0.0313\n",
      "Epochs [0/2], Step[4500/6000], Loss: 0.0583\n",
      "Epochs [0/2], Step[5000/6000], Loss: 0.0920\n",
      "Epochs [0/2], Step[5500/6000], Loss: 0.0053\n",
      "Epochs [1/2], Step[0/6000], Loss: 0.0253\n",
      "Epochs [1/2], Step[500/6000], Loss: 0.4723\n",
      "Epochs [1/2], Step[1000/6000], Loss: 0.1003\n",
      "Epochs [1/2], Step[1500/6000], Loss: 0.0068\n",
      "Epochs [1/2], Step[2000/6000], Loss: 0.0351\n",
      "Epochs [1/2], Step[2500/6000], Loss: 0.1865\n",
      "Epochs [1/2], Step[3000/6000], Loss: 0.0262\n",
      "Epochs [1/2], Step[3500/6000], Loss: 0.0144\n",
      "Epochs [1/2], Step[4000/6000], Loss: 0.0640\n",
      "Epochs [1/2], Step[4500/6000], Loss: 0.0678\n",
      "Epochs [1/2], Step[5000/6000], Loss: 0.0062\n",
      "Epochs [1/2], Step[5500/6000], Loss: 0.1738\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 2\n",
    "LR = 1e-3\n",
    "\n",
    "# Classifier will initialize SimpleNN with all the parameters passed\n",
    "# but some of them are not for the SimpleNN, but to be recorded in metadata\n",
    "model = Classifier(SimpleNN,\n",
    "    # These arguments are needed by SimpleNN, \n",
    "    # but passed as keywords to be recorded in meta\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=100,\n",
    "    num_classes=10,\n",
    "    # These arguments will be skipped by SimpleNN,\n",
    "    # but will be added to meta\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    lr=LR,\n",
    "    bs=BATCH_SIZE)\n",
    "model.fit(train_dl, NUM_EPOCHS, LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "Now we can evaluate model performance on test dataset. We pass the data and the dictionary with one metric. We can pass as many metrics as we like in the form of functions accepting ground-truth and predictions and returning metric value.  \n",
    "`f(true, pred) -> metric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 109.64it/s]\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_dl, {'acc': accuracy_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the metadata\n",
    "Let's examine metadata obtained from the model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '<__main__.Classifier object at 0x000001E93564CDF0>',\n",
       "  'created_at': DateTime(2022, 9, 4, 21, 17, 4, 730603, tzinfo=Timezone('UTC')),\n",
       "  'metrics': {'acc': 0.9685},\n",
       "  'params': {'input_size': 784,\n",
       "   'hidden_size': 100,\n",
       "   'num_classes': 10,\n",
       "   'num_epochs': 2,\n",
       "   'lr': 0.001,\n",
       "   'bs': 10},\n",
       "  'type': 'model',\n",
       "  'module': 'SimpleNN(\\n  (l1): Linear(in_features=784, out_features=100, bias=True)\\n  (l2): Linear(in_features=100, out_features=10, bias=True)\\n  (relu): ReLU()\\n)'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice several things. The model is tracking the time of creation. It's metrics in place as expected after evaluation.  \n",
    "Let's look at the params dict. We can see all the parameters that we passed using keywords in the wrapper. The wrapper recorded them in the metadata for us automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "It's time to save the trained model. We can just use model.save() method, but let's look at another Cascade's tool for model management.  \n",
    "It is called `ModelRepo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = cdm.ModelRepo('./repo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the repository of models. It manages a series of experiments over a sets of models of different architectures called model lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelLine of 0 models of <class '__main__.Classifier'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.add_line('linear_nn', Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model line is the manager of models with similar architecture, but different parameters or different epochs. It manages saving of model and its meta and also loading of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from model's metadata we would like to know on what data model was trained. Exactly for this we have metadata of our previously written data pipeline.  \n",
    "Let's update model's meta with the field for train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '<__main__.Classifier object at 0x000001E93564CDF0>',\n",
       "  'train_data': [{'name': '__main__.NoiseModifier',\n",
       "    'type': 'dataset',\n",
       "    'len': 60000},\n",
       "   {'name': 'cascade.data.dataset.Wrapper',\n",
       "    'desc': 'This is MNIST dataset of handwritten images, TRAIN PART',\n",
       "    'type': 'dataset',\n",
       "    'len': 60000,\n",
       "    'obj_type': \"<class 'torchvision.datasets.mnist.MNIST'>\"}],\n",
       "  'created_at': DateTime(2022, 9, 4, 21, 17, 4, 730603, tzinfo=Timezone('UTC')),\n",
       "  'metrics': {'acc': 0.9685},\n",
       "  'params': {'input_size': 784,\n",
       "   'hidden_size': 100,\n",
       "   'num_classes': 10,\n",
       "   'num_epochs': 2,\n",
       "   'lr': 0.001,\n",
       "   'bs': 10},\n",
       "  'type': 'model',\n",
       "  'module': 'SimpleNN(\\n  (l1): Linear(in_features=784, out_features=100, bias=True)\\n  (l2): Linear(in_features=100, out_features=10, bias=True)\\n  (relu): ReLU()\\n)'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.update_meta({'train_data': train_ds.get_meta()})\n",
    "model.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model is as easy as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo['linear_nn'].save(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will save the model to the path:  \n",
    "`repo/linear_nn/00000/model`  \n",
    "And metadata:  \n",
    "`repo/linear_nn/00000/meta.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeking inside repo\n",
    "To see model's metrics and parameters we don't need to manually go to the folders mentioned or print large metadata in console. Cascade has tools for conveniently show metrics. One of them is `MetricViewer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>num</th>\n",
       "      <th>created_at</th>\n",
       "      <th>saved</th>\n",
       "      <th>acc</th>\n",
       "      <th>input_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>bs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./repo\\linear_nn</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-04 21:17:04.730603+00:00</td>\n",
       "      <td>4 minutes after</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>784</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               line  num                       created_at            saved  \\\n",
       "0  ./repo\\linear_nn    0 2022-09-04 21:17:04.730603+00:00  4 minutes after   \n",
       "\n",
       "      acc  input_size  hidden_size  num_classes  num_epochs     lr  bs  \n",
       "0  0.9685         784          100           10           2  0.001  10  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv = cde.MetricViewer(repo)\n",
    "# We can show the table like this\n",
    "# mv.plot_table()\n",
    "# Or we can open web-application like this\n",
    "# mv.serve()\n",
    "# but it will not be rendered in the documentation, so...\n",
    "mv.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It accepts the repo object and can show tables of metrics and metadata. However, when the table is too big and we need more powerful tool, mv also has method `serve` that opens fully interactive table of metrics with the ability to sort and filter results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More experiments\n",
    "What if we want to automatically run a number of experiments and then choose the best model?  \n",
    "The workflow is pretty similar. In the example below we try to find the best option for hidden size of the model.  \n",
    "We define the set of parameters for our experiments and run them in loop every time saving the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'hidden_size': 10,  'num_epochs': 2, 'lr': 0.001, 'bs': 10},\n",
    "    {'hidden_size': 50,  'num_epochs': 2, 'lr': 0.001, 'bs': 10},\n",
    "    {'hidden_size': 100, 'num_epochs': 2, 'lr': 0.001, 'bs': 10}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs [0/2], Step[0/6000], Loss: 2.2945\n",
      "Epochs [0/2], Step[500/6000], Loss: 0.9460\n",
      "Epochs [0/2], Step[1000/6000], Loss: 0.6550\n",
      "Epochs [0/2], Step[1500/6000], Loss: 1.0467\n",
      "Epochs [0/2], Step[2000/6000], Loss: 0.3415\n",
      "Epochs [0/2], Step[2500/6000], Loss: 0.6182\n",
      "Epochs [0/2], Step[3000/6000], Loss: 0.7858\n",
      "Epochs [0/2], Step[3500/6000], Loss: 0.1378\n",
      "Epochs [0/2], Step[4000/6000], Loss: 0.4112\n",
      "Epochs [0/2], Step[4500/6000], Loss: 0.3582\n",
      "Epochs [0/2], Step[5000/6000], Loss: 0.2778\n",
      "Epochs [0/2], Step[5500/6000], Loss: 0.4385\n",
      "Epochs [1/2], Step[0/6000], Loss: 0.2049\n",
      "Epochs [1/2], Step[500/6000], Loss: 0.3557\n",
      "Epochs [1/2], Step[1000/6000], Loss: 0.7265\n",
      "Epochs [1/2], Step[1500/6000], Loss: 0.6659\n",
      "Epochs [1/2], Step[2000/6000], Loss: 0.7865\n",
      "Epochs [1/2], Step[2500/6000], Loss: 0.9827\n",
      "Epochs [1/2], Step[3000/6000], Loss: 1.1814\n",
      "Epochs [1/2], Step[3500/6000], Loss: 1.6972\n",
      "Epochs [1/2], Step[4000/6000], Loss: 0.7973\n",
      "Epochs [1/2], Step[4500/6000], Loss: 0.3721\n",
      "Epochs [1/2], Step[5000/6000], Loss: 0.4462\n",
      "Epochs [1/2], Step[5500/6000], Loss: 0.6195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 119.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs [0/2], Step[0/6000], Loss: 2.2951\n",
      "Epochs [0/2], Step[500/6000], Loss: 0.3524\n",
      "Epochs [0/2], Step[1000/6000], Loss: 0.2226\n",
      "Epochs [0/2], Step[1500/6000], Loss: 0.5415\n",
      "Epochs [0/2], Step[2000/6000], Loss: 0.1371\n",
      "Epochs [0/2], Step[2500/6000], Loss: 0.0284\n",
      "Epochs [0/2], Step[3000/6000], Loss: 0.0698\n",
      "Epochs [0/2], Step[3500/6000], Loss: 0.1873\n",
      "Epochs [0/2], Step[4000/6000], Loss: 0.1274\n",
      "Epochs [0/2], Step[4500/6000], Loss: 0.3228\n",
      "Epochs [0/2], Step[5000/6000], Loss: 0.0315\n",
      "Epochs [0/2], Step[5500/6000], Loss: 0.5258\n",
      "Epochs [1/2], Step[0/6000], Loss: 0.0319\n",
      "Epochs [1/2], Step[500/6000], Loss: 0.1378\n",
      "Epochs [1/2], Step[1000/6000], Loss: 0.1145\n",
      "Epochs [1/2], Step[1500/6000], Loss: 0.0600\n",
      "Epochs [1/2], Step[2000/6000], Loss: 0.0579\n",
      "Epochs [1/2], Step[2500/6000], Loss: 0.0629\n",
      "Epochs [1/2], Step[3000/6000], Loss: 0.0843\n",
      "Epochs [1/2], Step[3500/6000], Loss: 0.0116\n",
      "Epochs [1/2], Step[4000/6000], Loss: 0.5700\n",
      "Epochs [1/2], Step[4500/6000], Loss: 0.0630\n",
      "Epochs [1/2], Step[5000/6000], Loss: 0.0664\n",
      "Epochs [1/2], Step[5500/6000], Loss: 0.2906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:16<00:00, 61.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs [0/2], Step[0/6000], Loss: 2.3267\n",
      "Epochs [0/2], Step[500/6000], Loss: 0.1524\n",
      "Epochs [0/2], Step[1000/6000], Loss: 1.3480\n",
      "Epochs [0/2], Step[1500/6000], Loss: 0.5272\n",
      "Epochs [0/2], Step[2000/6000], Loss: 0.0733\n",
      "Epochs [0/2], Step[2500/6000], Loss: 0.1008\n",
      "Epochs [0/2], Step[3000/6000], Loss: 0.0959\n",
      "Epochs [0/2], Step[3500/6000], Loss: 0.0886\n",
      "Epochs [0/2], Step[4000/6000], Loss: 0.1491\n",
      "Epochs [0/2], Step[4500/6000], Loss: 0.2559\n",
      "Epochs [0/2], Step[5000/6000], Loss: 0.4157\n",
      "Epochs [0/2], Step[5500/6000], Loss: 0.0857\n",
      "Epochs [1/2], Step[0/6000], Loss: 0.0108\n",
      "Epochs [1/2], Step[500/6000], Loss: 0.4634\n",
      "Epochs [1/2], Step[1000/6000], Loss: 0.0855\n",
      "Epochs [1/2], Step[1500/6000], Loss: 0.1393\n",
      "Epochs [1/2], Step[2000/6000], Loss: 0.0404\n",
      "Epochs [1/2], Step[2500/6000], Loss: 0.3901\n",
      "Epochs [1/2], Step[3000/6000], Loss: 0.0669\n",
      "Epochs [1/2], Step[3500/6000], Loss: 0.0035\n",
      "Epochs [1/2], Step[4000/6000], Loss: 0.0137\n",
      "Epochs [1/2], Step[4500/6000], Loss: 0.0797\n",
      "Epochs [1/2], Step[5000/6000], Loss: 0.0015\n",
      "Epochs [1/2], Step[5500/6000], Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:13<00:00, 72.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for p in params:\n",
    "    model = Classifier(SimpleNN,\n",
    "        **p,\n",
    "        input_size=INPUT_SIZE,\n",
    "        num_classes=10)\n",
    "    model.fit(train_dl, **p)\n",
    "    model.evaluate(test_dl, {'acc': accuracy_score})\n",
    "    repo['linear_nn'].save(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "We can see the results of our experiments - all of them are present in the table and we can choose the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>num</th>\n",
       "      <th>created_at</th>\n",
       "      <th>saved</th>\n",
       "      <th>acc</th>\n",
       "      <th>input_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>bs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./repo\\linear_nn</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-04T21:17:04.730603+00:00</td>\n",
       "      <td>4 minutes after</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>784</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./repo\\linear_nn</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-09-04T21:21:36.876027+00:00</td>\n",
       "      <td>5 minutes after</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>784</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./repo\\linear_nn</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-04T21:27:07.507784+00:00</td>\n",
       "      <td>4 minutes after</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>784</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./repo\\linear_nn</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-09-04T21:31:15.790487+00:00</td>\n",
       "      <td>3 minutes after</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>784</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               line  num                        created_at            saved  \\\n",
       "0  ./repo\\linear_nn    0  2022-09-04T21:17:04.730603+00:00  4 minutes after   \n",
       "1  ./repo\\linear_nn    1  2022-09-04T21:21:36.876027+00:00  5 minutes after   \n",
       "2  ./repo\\linear_nn    2  2022-09-04T21:27:07.507784+00:00  4 minutes after   \n",
       "3  ./repo\\linear_nn    3  2022-09-04T21:31:15.790487+00:00  3 minutes after   \n",
       "\n",
       "      acc  input_size  hidden_size  num_classes  num_epochs     lr  bs  \n",
       "0  0.9685         784          100           10           2  0.001  10  \n",
       "1  0.8851         784           10           10           2  0.001  10  \n",
       "2  0.9607         784           50           10           2  0.001  10  \n",
       "3  0.9627         784          100           10           2  0.001  10  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv = cde.MetricViewer(repo)\n",
    "# mv.plot_table()\n",
    "mv.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also:\n",
    "- [Pipeline building](pipeline_building.html) - (Previous example)\n",
    "- [Documentation](https://oxid15.github.io/cascade/)\n",
    "- [Key concepts](https://oxid15.github.io/cascade/concepts.html)\n",
    "- [Code reference](https://oxid15.github.io/cascade/modules.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "87f4f7b13864d85c4a2c9cc8379c2fc28050103468031879c35c8b8ef7dd6990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
