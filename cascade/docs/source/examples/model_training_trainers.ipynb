{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training using trainers\n",
    "This use-case is model training - the same, but now the usage of Trainer will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /home/ilia/local/cascade_proj/venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ilia/local/cascade_proj/venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install torchvision\n",
    "# !pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cascade.data as cdd\n",
    "import cascade.models as cdm\n",
    "from cascade.utils.torch import TorchModel\n",
    "from cascade.utils.sklearn import SkMetric\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.0-alpha'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cascade\n",
    "cascade.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data pipeline\n",
    "This part will be without comments. For more detailed explanations, please see [pipeline building example](https://oxid15.github.io/cascade/examples/pipeline_building.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_ROOT = 'data'\n",
    "INPUT_SIZE = 784\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:11<00:00, 840403.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 585963.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2002218.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 760469.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NoiseModifier(cdd.Modifier):\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self._dataset[index]\n",
    "        img += torch.rand_like(img) * 0.1\n",
    "        img = torch.clip(img, 0, 255)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_ds = torchvision.datasets.MNIST(root=MNIST_ROOT,\n",
    "                                     train=True, \n",
    "                                     transform=F.to_tensor,\n",
    "                                     download=True)\n",
    "test_ds = torchvision.datasets.MNIST(root=MNIST_ROOT, \n",
    "                                    train=False, \n",
    "                                    transform=F.to_tensor)\n",
    "\n",
    "train_ds = cdd.Wrapper(train_ds)\n",
    "train_ds.describe(\"This is MNIST dataset of handwritten images, TRAIN PART\")\n",
    "test_ds = cdd.Wrapper(test_ds)\n",
    "\n",
    "train_ds = NoiseModifier(train_ds)\n",
    "test_ds = NoiseModifier(test_ds)\n",
    "\n",
    "# We will constraint the number of samples to speed up learning in example\n",
    "train_ds = cdd.CyclicSampler(train_ds, 10000)\n",
    "test_ds = cdd.CyclicSampler(test_ds, 5000)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_ds, \n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(dataset=test_ds,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'cascade.data.cyclic_sampler.CyclicSampler',\n",
       "  'description': None,\n",
       "  'tags': [],\n",
       "  'comments': [],\n",
       "  'links': [],\n",
       "  'type': 'dataset',\n",
       "  'len': 10000},\n",
       " {'name': '__main__.NoiseModifier',\n",
       "  'description': None,\n",
       "  'tags': [],\n",
       "  'comments': [],\n",
       "  'links': [],\n",
       "  'type': 'dataset',\n",
       "  'len': 60000},\n",
       " {'name': 'cascade.data.dataset.Wrapper',\n",
       "  'description': 'This is MNIST dataset of handwritten images, TRAIN PART',\n",
       "  'tags': [],\n",
       "  'comments': [],\n",
       "  'links': [],\n",
       "  'type': 'dataset',\n",
       "  'len': 60000,\n",
       "  'obj_type': \"<class 'torchvision.datasets.mnist.MNIST'>\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "Before training we need to define our model. We need regular nn.Module and Cascade's wrapper around it.  \n",
    "  \n",
    "Module defined without any specific changes in the original pytorch code, except now it accepts `*args` and `**kwargs` in `__init__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, y):\n",
    "         out = self.l1(y)\n",
    "         out = self.relu(out)\n",
    "         out = self.l2(out)\n",
    "\n",
    "         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Cascade's wrapper is defined. The most of the interactions with pytorch modules is already implemented in `cascade.utils.TorchModel` so we need to only define how to train and evaluate this model.  \n",
    "  \n",
    "The difference between previous example and this one is in the `fit` function - now it only fits one epoch per call and doesn't need additional logging - Trainer will cover this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(TorchModel):\n",
    "    # In train we copy-paste regular pytorch trainloop, \n",
    "    # but use self._model, where our SimpleNN is placed\n",
    "    def fit(self, train_dl, lr, *args, **kwargs):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.Adam(self._model.parameters(), lr=lr)\n",
    "\n",
    "        ds_size = len(train_dl)\n",
    "        for x, (imgs, labels) in enumerate(train_dl): \n",
    "            imgs = imgs.reshape(-1, self._model.input_size)\n",
    "\n",
    "            out = self._model(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step() \n",
    "\n",
    "\n",
    "    # Evaluate function takes the metrics from arguments\n",
    "    # and populates self.metrics without returning anything\n",
    "    def evaluate(self, test_dl, metrics, *args, **kwargs):\n",
    "        pred = []\n",
    "        gt = []\n",
    "        for imgs, labels in tqdm(test_dl): \n",
    "            imgs = imgs.reshape(-1, self._model.input_size)\n",
    "            out = torch.argmax(self._model(imgs, *args, **kwargs), -1)\n",
    "\n",
    "            pred.append(out)\n",
    "            gt.append(labels)\n",
    "\n",
    "        pred = torch.concat(pred).detach().numpy()\n",
    "        gt = torch.concat(gt).detach().numpy()\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric.compute(gt, pred)\n",
    "            self.add_metric(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "LR = 1e-3\n",
    "\n",
    "# Classifier will initialize SimpleNN with all the parameters passed\n",
    "# but some of them are not for the SimpleNN, but to be recorded in metadata\n",
    "model = Classifier(SimpleNN,\n",
    "    # These arguments are needed by SimpleNN, \n",
    "    # but passed as keywords to be recorded in meta\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=100,\n",
    "    num_classes=10,\n",
    "    # These arguments will be skipped by SimpleNN,\n",
    "    # but will be added to meta\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    lr=LR,\n",
    "    bs=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trainer\n",
    "Let's set up logging first to catch trainer's logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    level='INFO'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer accepts ModelRepo object or just a path \n",
    "trainer = cdm.BasicTrainer('trainer_repo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Training started with parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.models.trainer:repo is ModelRepo in trainer_repo of 1 lines\n",
      "INFO:cascade.models.trainer:line is 00000\n",
      "INFO:cascade.models.trainer:training will last 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 66.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 0\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.884, created_at=2024-06-12 14:52:57.222170+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:06<00:00, 75.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 1\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.8878, created_at=2024-06-12 14:52:57.222170+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:05<00:00, 85.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 2\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9066, created_at=2024-06-12 14:52:57.222170+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:06<00:00, 72.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 3\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9148, created_at=2024-06-12 14:52:57.222170+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:06<00:00, 82.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 4\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)\n",
      "INFO:cascade.models.trainer:Training finished in 2 minutes\n",
      "INFO:cascade.models.trainer:repo was ModelRepo in trainer_repo of 1 lines\n",
      "INFO:cascade.models.trainer:line was 00000\n",
      "INFO:cascade.models.trainer:training ended on 4 epoch\n",
      "INFO:cascade.models.trainer:Parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.models.trainer:Metrics:\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The main method of course is train\n",
    "# It will do all the stuff needed for us\n",
    "# including training, evaluating, saving and logging\n",
    "trainer.train(\n",
    "    model,\n",
    "    train_data=train_dl,\n",
    "    test_data=test_dl,\n",
    "    train_kwargs={'lr': LR, 'bs': BATCH_SIZE}, # will be passed into model.fit()\n",
    "    test_kwargs={\"metrics\": [SkMetric(\"accuracy_score\")]}, # will be passed into model.evaluate()\n",
    "    epochs=NUM_EPOCHS,\n",
    "    start_from=None, # can start from checkpoint if line is specified,\n",
    "    save_strategy=2,\n",
    "    eval_strategy=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "We can obtain the results of training from trainer's meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'cascade.models.trainer.BasicTrainer',\n",
       "  'description': None,\n",
       "  'tags': [],\n",
       "  'comments': [],\n",
       "  'links': [],\n",
       "  'metrics': [[SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)]],\n",
       "  'repo': [{'name': 'ModelRepo in trainer_repo of 1 lines',\n",
       "    'description': None,\n",
       "    'tags': [],\n",
       "    'comments': [],\n",
       "    'links': [],\n",
       "    'updated_at': '2024-06-12 14:56:31.085887+00:00',\n",
       "    'root': 'trainer_repo',\n",
       "    'len': 1,\n",
       "    'type': 'repo',\n",
       "    'cascade_version': '0.14.0-alpha',\n",
       "    'created_at': '2024-06-12 14:52:55.415058+00:00'}],\n",
       "  'training_started_at': DateTime(2024, 6, 12, 17, 52, 57, 234693, tzinfo=Timezone('Europe/Moscow')),\n",
       "  'training_ended_at': DateTime(2024, 6, 12, 17, 55, 1, 952155, tzinfo=Timezone('Europe/Moscow'))}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from checkpoint\n",
    "Let's try continue learning where we finished using the same line as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Training started with parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.models.trainer:repo is ModelRepo in trainer_repo of 1 lines\n",
      "INFO:cascade.models.trainer:line is 00000\n",
      "INFO:cascade.models.trainer:started from model 4\n",
      "INFO:cascade.models.trainer:training will last 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:09<00:00, 50.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 0\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9246, created_at=2024-06-12 14:56:48.094497+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:06<00:00, 75.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 1\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9282, created_at=2024-06-12 14:56:48.094497+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:08<00:00, 60.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 2\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.928, created_at=2024-06-12 14:56:48.094497+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:10<00:00, 45.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9244, created_at=2024-06-12 14:56:48.094497+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 77.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 4\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9298, created_at=2024-06-12 14:56:48.094497+00:00)\n",
      "INFO:cascade.models.trainer:Training finished in 2 minutes\n",
      "INFO:cascade.models.trainer:repo was ModelRepo in trainer_repo of 1 lines\n",
      "INFO:cascade.models.trainer:line was 00000\n",
      "INFO:cascade.models.trainer:started from model 4\n",
      "INFO:cascade.models.trainer:training ended on 4 epoch\n",
      "INFO:cascade.models.trainer:Parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.models.trainer:Metrics:\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9298, created_at=2024-06-12 14:56:48.094497+00:00)\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    model,\n",
    "    train_data=train_dl,\n",
    "    test_data=test_dl,\n",
    "    train_kwargs={'lr': LR, 'bs': BATCH_SIZE},\n",
    "    test_kwargs={'metrics': [SkMetric(\"accuracy_score\")]},\n",
    "    epochs=5,\n",
    "    start_from='00000',\n",
    "    save_strategy=4,\n",
    "    eval_strategy=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.92, created_at=2024-06-12 14:52:57.222170+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9298, created_at=2024-06-12 14:56:48.094497+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9298, created_at=2024-06-12 14:56:48.094497+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9298, created_at=2024-06-12 14:56:48.094497+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9298, created_at=2024-06-12 14:56:48.094497+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9298, created_at=2024-06-12 14:56:48.094497+00:00)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also:\n",
    "- [Pipeline building](pipeline_building.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cascade_full_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faab9700dd378963078e8736d2f2a2135ebae0340eb64481dd59710303e6f8c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
