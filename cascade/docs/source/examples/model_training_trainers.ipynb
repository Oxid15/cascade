{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training using trainers\n",
    "This use-case is model training - the same, but now the usage of Trainer will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\илья\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import cascade.data as cdd\n",
    "import cascade.models as cdm\n",
    "from cascade.utils.torch import TorchModel\n",
    "from cascade.utils.sklearn import SkMetric\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.13.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cascade\n",
    "cascade.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data pipeline\n",
    "This part will be without comments. For more detailed explanations, please see [pipeline building example](https://oxid15.github.io/cascade/examples/pipeline_building.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_ROOT = 'data'\n",
    "INPUT_SIZE = 784\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseModifier(cdd.Modifier):\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self._dataset[index]\n",
    "        img += torch.rand_like(img) * 0.1\n",
    "        img = torch.clip(img, 0, 255)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_ds = torchvision.datasets.MNIST(root=MNIST_ROOT,\n",
    "                                     train=True, \n",
    "                                     transform=F.to_tensor,\n",
    "                                     download=True)\n",
    "test_ds = torchvision.datasets.MNIST(root=MNIST_ROOT, \n",
    "                                    train=False, \n",
    "                                    transform=F.to_tensor)\n",
    "\n",
    "train_ds = cdd.Wrapper(train_ds)\n",
    "train_ds.describe(\"This is MNIST dataset of handwritten images, TRAIN PART\")\n",
    "test_ds = cdd.Wrapper(test_ds)\n",
    "\n",
    "train_ds = NoiseModifier(train_ds)\n",
    "test_ds = NoiseModifier(test_ds)\n",
    "\n",
    "# We will constraint the number of samples to speed up learning in example\n",
    "train_ds = cdd.CyclicSampler(train_ds, 10000)\n",
    "test_ds = cdd.CyclicSampler(test_ds, 5000)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_ds, \n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(dataset=test_ds,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'cascade.data.cyclic_sampler.CyclicSampler',\n",
       "  'description': None,\n",
       "  'tags': [],\n",
       "  'comments': [],\n",
       "  'links': [],\n",
       "  'type': 'dataset',\n",
       "  'len': 10000},\n",
       " {'name': '__main__.NoiseModifier',\n",
       "  'description': None,\n",
       "  'tags': [],\n",
       "  'comments': [],\n",
       "  'links': [],\n",
       "  'type': 'dataset',\n",
       "  'len': 60000},\n",
       " {'name': 'cascade.data.dataset.Wrapper',\n",
       "  'description': 'This is MNIST dataset of handwritten images, TRAIN PART',\n",
       "  'tags': [],\n",
       "  'comments': [],\n",
       "  'links': [],\n",
       "  'type': 'dataset',\n",
       "  'len': 60000,\n",
       "  'obj_type': \"<class 'torchvision.datasets.mnist.MNIST'>\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "Before training we need to define our model. We need regular nn.Module and Cascade's wrapper around it.  \n",
    "  \n",
    "Module defined without any specific changes in the original pytorch code, except now it accepts `*args` and `**kwargs` in `__init__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, y):\n",
    "         out = self.l1(y)\n",
    "         out = self.relu(out)\n",
    "         out = self.l2(out)\n",
    "\n",
    "         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Cascade's wrapper is defined. The most of the interaction with pytorch modules are already implemented in `cascade.utils.TorchModel` so we need to only define how to train and evaluate the model.  \n",
    "  \n",
    "The difference between previous example and this in the `fit` function - now it only fits one epoch per call and doesn't need additional logging - Trainer will cover this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(TorchModel):\n",
    "    # In train we copy-paste regular pytorch trainloop, \n",
    "    # but use self._model, where our SimpleNN is placed\n",
    "    def fit(self, train_dl, lr, *args, **kwargs):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.Adam(self._model.parameters(), lr=lr)\n",
    "\n",
    "        ds_size = len(train_dl)\n",
    "        for x, (imgs, labels) in enumerate(train_dl): \n",
    "            imgs = imgs.reshape(-1, self._model.input_size)\n",
    "\n",
    "            out = self._model(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step() \n",
    "\n",
    "\n",
    "    # Evaluate function takes the metrics from arguments\n",
    "    # and populates self.metrics without returning anything\n",
    "    def evaluate(self, test_dl, metrics, *args, **kwargs):\n",
    "        pred = []\n",
    "        gt = []\n",
    "        for imgs, labels in tqdm(test_dl): \n",
    "            imgs = imgs.reshape(-1, self._model.input_size)\n",
    "            out = torch.argmax(self._model(imgs, *args, **kwargs), -1)\n",
    "\n",
    "            pred.append(out)\n",
    "            gt.append(labels)\n",
    "\n",
    "        pred = torch.concat(pred).detach().numpy()\n",
    "        gt = torch.concat(gt).detach().numpy()\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric.compute(gt, pred)\n",
    "            self.add_metric(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "LR = 1e-3\n",
    "\n",
    "# Classifier will initialize SimpleNN with all the parameters passed\n",
    "# but some of them are not for the SimpleNN, but to be recorded in metadata\n",
    "model = Classifier(SimpleNN,\n",
    "    # These arguments are needed by SimpleNN, \n",
    "    # but passed as keywords to be recorded in meta\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=100,\n",
    "    num_classes=10,\n",
    "    # These arguments will be skipped by SimpleNN,\n",
    "    # but will be added to meta\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    lr=LR,\n",
    "    bs=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trainer\n",
    "Let's set up logging first to catch trainer's logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    level='INFO'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer accepts ModelRepo object or just a path \n",
    "trainer = cdm.BasicTrainer('trainer_repo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Training started with parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.models.trainer:repo is ModelRepo in trainer_repo of 1 lines\n",
      "INFO:cascade.models.trainer:line is 00000\n",
      "INFO:cascade.models.trainer:training will last 10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 89.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9348, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 91.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 1\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9376, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:10<00:00, 46.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 2\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9378, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:08<00:00, 57.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 3\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9338, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 72.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 4\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9336, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 68.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.937, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:08<00:00, 59.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 6\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9416, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 73.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 7\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9256, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:11<00:00, 43.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9396, created_at=2023-11-06T14:21:51.679983+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 69.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)\n",
      "INFO:cascade.models.trainer:Training finished in 4 minutes\n"
     ]
    }
   ],
   "source": [
    "# The main method of course is train\n",
    "# It will do all the stuff needed for us\n",
    "# including training, evaluating, saving and logging\n",
    "trainer.train(\n",
    "    model,\n",
    "    train_data=train_dl,\n",
    "    test_data=test_dl,\n",
    "    train_kwargs={'lr': LR, 'bs': BATCH_SIZE}, # will be passed into model.fit()\n",
    "    test_kwargs={\"metrics\": [SkMetric(\"accuracy_score\")]}, # will be passed into model.evaluate()\n",
    "    epochs=NUM_EPOCHS,\n",
    "    start_from=None, # can start from checkpoint if line is specified,\n",
    "    save_strategy=2,\n",
    "    eval_strategy=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "We can obtain the results of training from trainer's meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'cascade.models.trainer.BasicTrainer',\n",
       "  'description': None,\n",
       "  'tags': [],\n",
       "  'comments': [],\n",
       "  'links': [],\n",
       "  'metrics': [[SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       "   [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)]],\n",
       "  'repo': [{'name': 'ModelRepo in trainer_repo of 1 lines',\n",
       "    'description': None,\n",
       "    'tags': [],\n",
       "    'comments': [],\n",
       "    'links': [],\n",
       "    'updated_at': DateTime(2023, 11, 6, 14, 26, 20, 110614, tzinfo=Timezone('UTC')),\n",
       "    'root': 'trainer_repo',\n",
       "    'len': 1,\n",
       "    'type': 'repo',\n",
       "    'cascade_version': '0.13.0'}],\n",
       "  'train_start_at': DateTime(2023, 11, 6, 17, 21, 51, 711936, tzinfo=Timezone('Europe/Moscow')),\n",
       "  'train_end_at': DateTime(2023, 11, 6, 17, 26, 20, 26633, tzinfo=Timezone('Europe/Moscow'))}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from checkpoint\n",
    "Let's try continue learning where we finished using the same line as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:cascade.models.trainer:Model 10 files were not found\n",
      "Error when loading an artifact - c:\\cascade\\cascade\\docs\\source\\examples\\trainer_repo\\00000\\00010\\artifacts is not a folder\n",
      "WARNING:cascade.models.trainer:Model 9 files were not found\n",
      "Error when loading an artifact - c:\\cascade\\cascade\\docs\\source\\examples\\trainer_repo\\00000\\00009\\artifacts is not a folder\n",
      "INFO:cascade.models.trainer:Training started with parameters:\n",
      "{'lr': 0.001, 'bs': 10}\n",
      "INFO:cascade.models.trainer:repo is ModelRepo in trainer_repo of 1 lines\n",
      "INFO:cascade.models.trainer:line is 00000\n",
      "INFO:cascade.models.trainer:started from model 8\n",
      "INFO:cascade.models.trainer:training will last 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:13<00:00, 36.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 0\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.941, created_at=2023-11-06T14:27:45.955057+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 65.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 1\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.936, created_at=2023-11-06T14:27:45.955057+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:21<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 2\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.936, created_at=2023-11-06T14:27:45.955057+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:12<00:00, 40.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 3\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.941, created_at=2023-11-06T14:27:45.955057+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:11<00:00, 45.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cascade.models.trainer:Epoch: 4\n",
      "INFO:cascade.models.trainer:SkMetric(name=accuracy_score, value=0.9364, created_at=2023-11-06T14:27:45.955057+00:00)\n",
      "INFO:cascade.models.trainer:Training finished in 3 minutes\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    model,\n",
    "    train_data=train_dl,\n",
    "    test_data=test_dl,\n",
    "    train_kwargs={'lr': LR, 'bs': BATCH_SIZE},\n",
    "    test_kwargs={'metrics': [SkMetric(\"accuracy_score\")]},\n",
    "    epochs=5,\n",
    "    start_from='00000',\n",
    "    save_strategy=4,\n",
    "    eval_strategy=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9394, created_at=2023-11-06T14:21:51.679983+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9364, created_at=2023-11-06T14:27:45.955057+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9364, created_at=2023-11-06T14:27:45.955057+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9364, created_at=2023-11-06T14:27:45.955057+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9364, created_at=2023-11-06T14:27:45.955057+00:00)],\n",
       " [SkMetric(name=accuracy_score, value=0.9364, created_at=2023-11-06T14:27:45.955057+00:00)]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also:\n",
    "- [Pipeline building](pipeline_building.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cascade_full_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faab9700dd378963078e8736d2f2a2135ebae0340eb64481dd59710303e6f8c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
