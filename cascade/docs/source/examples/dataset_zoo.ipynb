{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Zoo\n",
    "Cascade by itself is **DIY ML-engineering solution**. This means that it provides certain basics on top of which you can easily build own ML-workflow.  \n",
    "Cascade has plenty of solutions - basic that are added to the core and more specific that are in the special `utils` module. And if you didn't found suitable component, you can write it yourself.  \n",
    "Here some of them are presented. These are the `Dataset`s - building blocks of Cascade's pipelines, their description and short examples of how to use them in your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0-alpha\n"
     ]
    }
   ],
   "source": [
    "import cascade\n",
    "print(cascade.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cascade import data as cdd\n",
    "from cascade import utils as cdu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappers\n",
    "If your solution has some data source that is already accesible in python-code, but you need to plug it in Cascade's workflow it may be all you need. `Wrapper` gives the items from the source one by one, adding some info about the undelying data to its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 "
     ]
    }
   ],
   "source": [
    "ds = cdd.Wrapper([0, 1, 2, 3, 4]) # Here for simplicity the list of numbers is a data source\n",
    "\n",
    "for item in ds:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterators\n",
    "If data source doesn't have length - you cannot use `Wrapper`s, but it is not a problem, you can use `Iterator`s instead! It is basically the same dataset, but using different interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 "
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for number in range(5):\n",
    "        yield number\n",
    "\n",
    "ds = cdd.Iterator(gen())\n",
    "\n",
    "for item in ds:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ApplyModifier\n",
    "The pipelines are frequently applying some python-functions to the items in datasets. In Cascade this is done by using `ApplyModifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 4 9 16 "
     ]
    }
   ],
   "source": [
    "# The function that will be applied\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "ds = cdd.Wrapper([0, 1, 2, 3, 4])\n",
    "ds = cdd.ApplyModifier(ds, square) # ds now a pipeline of two stages\n",
    "\n",
    "for item in ds:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "ds_1 = cdd.Wrapper([0, 1, 2, 3, 4])\n",
    "ds_2 = cdd.Wrapper([5, 6, 7, 8, 9])\n",
    "\n",
    "ds = cdd.Concatenator((ds_1, ds_2))\n",
    "\n",
    "for item in ds:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CyclicSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 0 1 2 3 4 0 "
     ]
    }
   ],
   "source": [
    "ds = cdd.Wrapper([0, 1, 2, 3, 4])\n",
    "ds = cdd.CyclicSampler(ds, 11)\n",
    "\n",
    "for item in ds:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0 3 3 3 1 3 2 4 0 0 "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "ds = cdd.Wrapper([0, 1, 2, 3, 4])\n",
    "ds = cdd.RandomSampler(ds, 11)\n",
    "\n",
    "for item in ds:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RangeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 5 7 9 "
     ]
    }
   ],
   "source": [
    "ds = cdd.Wrapper([0, 1, 2, 3, 4 , 5, 6, 7, 8, 9, 10])\n",
    "ds = cdd.RangeSampler(ds, 1, 10, 2)\n",
    "\n",
    "for item in ds:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BruteforceCacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class LongLoadingDataSource(cdd.Dataset):\n",
    "    def __init__(self, length, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._length = length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        time.sleep(1)\n",
    "        return index\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "ds = LongLoadingDataSource(10)\n",
    "ds = cdd.BruteforceCacher(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "ds = LongLoadingDataSource(10)\n",
    "ds = cdd.BruteforceCacher(ds)\n",
    "ds = cdd.Pickler('ds.pkl', ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5006.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ds = cdd.Pickler('ds.pkl')\n",
    "\n",
    "for item in tqdm(ds):\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequentialCacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "loaded 0\n",
      "loaded 1\n",
      "loaded 2\n",
      "loaded 3\n",
      "loaded 4\n",
      "loaded 5\n",
      "loaded 6\n",
      "loaded 7\n",
      "loaded 8\n",
      "loaded 9\n",
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n",
      "Step 8\n",
      "Step 9\n",
      "Step 10\n",
      "loaded 10\n",
      "loaded 11\n",
      "loaded 12\n",
      "loaded 13\n",
      "loaded 14\n",
      "loaded 15\n",
      "loaded 16\n",
      "loaded 17\n",
      "loaded 18\n",
      "loaded 19\n"
     ]
    }
   ],
   "source": [
    "from cascade import data as cdd\n",
    "\n",
    "\n",
    "class AlertOnLoad(cdd.Dataset):\n",
    "    def __init__(self, length, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._length = length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print(f'loaded {index}')\n",
    "        return index\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "\n",
    "ds = AlertOnLoad(100)\n",
    "ds = cdd.SequentialCacher(ds, 10)\n",
    "\n",
    "for i in range(11):\n",
    "    print(f'Step {i}')\n",
    "    ds[i] # Load the element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VersionAssigner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from cascade import data as cdd\n",
    "\n",
    "ds = cdd.Wrapper([0, 1, 2, 3, 4])\n",
    "ds = cdd.VersionAssigner(ds, 'ds_version_log.yml')\n",
    "print(ds.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "ds = cdd.Wrapper([0, 1, 2, 3, 4])\n",
    "ds = cdd.Modifier(ds)\n",
    "ds = cdd.VersionAssigner(ds, 'ds_version_log.yml')\n",
    "print(ds.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n"
     ]
    }
   ],
   "source": [
    "ds = cdd.Wrapper([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "ds = cdd.Modifier(ds)\n",
    "ds = cdd.VersionAssigner(ds, 'ds_version_log.yml')\n",
    "print(ds.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6, 2\n"
     ]
    }
   ],
   "source": [
    "from cascade import data as cdd\n",
    "\n",
    "\n",
    "ds = cdd.Wrapper([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "train_ds, test_ds = cdd.split(ds, 0.8)\n",
    "\n",
    "print(len(train_ds), len(test_ds), sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87f4f7b13864d85c4a2c9cc8379c2fc28050103468031879c35c8b8ef7dd6990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
