{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "This use-case is model training.  \n",
    "Previous part is the pipeline building and is taken without comments.  \n",
    "For more detailed description of it see Pipeline building example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\илья\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cascade.data as cdd\n",
    "import cascade.models as cdm\n",
    "import cascade.utils as cdu\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_ROOT = 'data'\n",
    "INPUT_SIZE = 784\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseModifier(cdd.Modifier):\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self._dataset[index] # get the data from Wrapper, which is _dataset for this Modifier\n",
    "        img += torch.rand_like(img) * 0.1 # apply random noise with fixed magnitude\n",
    "        img = torch.clip(img, 0, 255)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_ds = torchvision.datasets.MNIST(root=MNIST_ROOT,\n",
    "                                     train=True, \n",
    "                                     transform=F.to_tensor,\n",
    "                                     download=True)\n",
    "test_ds = torchvision.datasets.MNIST(root=MNIST_ROOT, \n",
    "                                    train=False, \n",
    "                                    transform=F.to_tensor)\n",
    "\n",
    "train_ds = cdd.Wrapper(train_ds, \n",
    "    meta_prefix={\n",
    "        'desc': 'This is MNIST dataset of handwritten images, TRAIN PART'\n",
    "    })\n",
    "\n",
    "test_ds = cdd.Wrapper(test_ds,\n",
    "    meta_prefix={\n",
    "        'desc': 'This is MNIST dataset of handwritten images, TEST PART'\n",
    "    })\n",
    "\n",
    "train_ds = cdd.CyclicSampler(NoiseModifier(train_ds), 200)\n",
    "test_ds = NoiseModifier(test_ds)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_ds, \n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(dataset=test_ds,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'cascade.data.cyclic_sampler.CyclicSampler',\n",
       "  'type': 'dataset',\n",
       "  'len': 200},\n",
       " {'name': '__main__.NoiseModifier', 'type': 'dataset', 'len': 60000},\n",
       " {'name': 'cascade.data.dataset.Wrapper',\n",
       "  'desc': 'This is MNIST dataset of handwritten images, TRAIN PART',\n",
       "  'type': 'dataset',\n",
       "  'len': 60000,\n",
       "  'obj_type': torchvision.datasets.mnist.MNIST}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, y):\n",
    "         out = self.l1(y)\n",
    "         out = self.relu(out)\n",
    "         out = self.l2(out)\n",
    "\n",
    "         return out\n",
    "\n",
    "\n",
    "class Classifier(cdu.TorchModel):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(self._model.parameters(), lr=lr)\n",
    "\n",
    "    ds_size = len(train_dl)\n",
    "    for epoch in range(num_epochs):\n",
    "        for x, (imgs, labels) in enumerate(train_dl): \n",
    "            imgs = imgs.reshape(-1, self._model.input_size)\n",
    "\n",
    "            out = self._model(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step() \n",
    "\n",
    "            if x % 10 == 0:\n",
    "                print (f'Epochs [{epoch}/{num_epochs}], Step[{x}/{ds_size}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes from 1 to 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\cascade\\cascade\\docs\\source\\examples\\model_training.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=0'>1</a>\u001b[0m NUM_EPOCHS \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=1'>2</a>\u001b[0m LR \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m TorchModel(SimpleModel, INPUT_SIZE, \u001b[39m100\u001b[39;49m, \u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=4'>5</a>\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=5'>6</a>\u001b[0m     lr\u001b[39m=\u001b[39;49mLR, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=6'>7</a>\u001b[0m     bs\u001b[39m=\u001b[39;49mBATCH_SIZE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mfit(train_dl, NUM_EPOCHS, LR)\n",
      "\u001b[1;32mc:\\cascade\\cascade\\docs\\source\\examples\\model_training.ipynb Cell 7\u001b[0m in \u001b[0;36mTorchModel.__init__\u001b[1;34m(self, model_class, *args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model_class, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=20'>21</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m model_class(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/cascade/cascade/docs/source/examples/model_training.ipynb#ch0000025?line=21'>22</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes from 1 to 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 2\n",
    "LR = 1e-3\n",
    "\n",
    "model = TorchModel(SimpleModel, INPUT_SIZE, 100, 10,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    lr=LR, \n",
    "    bs=BATCH_SIZE)\n",
    "model.fit(train_dl, NUM_EPOCHS, LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '<__main__.SpecificWrapper object at 0x00000184DBE17BB0>',\n",
       "  'created_at': DateTime(2022, 7, 24, 20, 25, 25, 794859, tzinfo=Timezone('UTC')),\n",
       "  'metrics': {},\n",
       "  'params': {'hidden_size': 100, 'num_epochs': 2, 'lr': 0.001, 'bs': 10},\n",
       "  'type': 'model'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1eab4963f8bb4f252819dbce5af8175fe150793bc166a28b75f990b50d08af03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
